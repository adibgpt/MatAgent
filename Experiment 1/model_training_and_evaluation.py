import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Load the dataset\ndf = pd.read_csv('data.csv')\n\n# Preprocessing: Drop non-numeric columns and handle missing values\ndf = df.select_dtypes(include=[np.number]).dropna()\n\n# Features and target variable\nX = df.drop('experimental_band_gap', axis=1)\ny = df['experimental_band_gap']\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize models\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(),\n    'Gradient Boosting': GradientBoostingRegressor(),\n    'Support Vector Regressor': SVR()\n}\n\n# Store results\nresults = {}\n\n# Train and evaluate each model\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    results[name] = {'MSE': mse, 'R²': r2}\n\n# Convert results to DataFrame\nresults_df = pd.DataFrame(results).T\n\n# Visualization of R² and MSE\nfig, ax1 = plt.subplots(figsize=(10, 6))\n\n# Create bar plots for R² and MSE\nresults_df['R²'].plot(kind='bar', color='b', ax=ax1, position=0, width=0.4, label='R²')\nresults_df['MSE'].plot(kind='bar', color='r', ax=ax1, position=1, width=0.4, label='MSE')\n\n# Adding labels and title\nax1.set_ylabel('Scores')\nax1.set_title('Model Performance: R² and MSE')\nax1.legend()\n\n# Save the figure\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig('model_performance.png')\nplt.show()